{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import tempfile\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32001L0029'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print('Internet connected')\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    main_content = soup.find('div', {'id': 'TexteOnly'}) \n",
    "\n",
    "    if main_content:\n",
    "        all_text = []\n",
    "        paragraphs = main_content.find_all('p')\n",
    "        for i, p in enumerate(paragraphs):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            paragraph_text = p.get_text(strip=True)\n",
    "            all_text.append(paragraph_text)\n",
    "        full_text = \"\\n\".join(all_text)\n",
    "    else:\n",
    "        print(\"Main content not found.\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \"]\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(full_text)\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "\n",
    "embeddings_ollama = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "model_ollama = ChatOllama(model=\"llama3.2\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "def clear_vectorstore(vectorstore_path):\n",
    "    if os.path.exists(vectorstore_path):\n",
    "        shutil.rmtree(vectorstore_path)  # Removes the entire directory and its contents\n",
    "        print(f\"Vectorstore at '{vectorstore_path}' has been cleared.\")\n",
    "    else:\n",
    "        print(f\"No vectorstore found at '{vectorstore_path}'.\")\n",
    "\n",
    "# Example usage\n",
    "clear_vectorstore(\"data/vectorstore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorstore(chunks, embedding_function, vectorstore_path):\n",
    "    unique_chunks = list(set(chunks))\n",
    "\n",
    "    vectorstore = Chroma.from_texts(\n",
    "        texts=unique_chunks,\n",
    "        embedding=embedding_function,\n",
    "        persist_directory=vectorstore_path\n",
    "    )\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def insert_if_not_exists(chunks, embedding_function, vectorstore_path):\n",
    "    try:\n",
    "        vectorstore = Chroma(persist_directory=vectorstore_path, embedding_function=embedding_function)\n",
    "    except:\n",
    "        vectorstore = Chroma.from_texts(texts=[], embedding=embedding_function, persist_directory=vectorstore_path)\n",
    "\n",
    "    new_chunks = []\n",
    "    for chunk in chunks:\n",
    "        embedding = embedding_function.embed_query(chunk)\n",
    "        results = vectorstore.similarity_search_by_vector(embedding, k=1)\n",
    "        if not results or results[0].page_content != chunk:\n",
    "            new_chunks.append(chunk)\n",
    "\n",
    "    if new_chunks:\n",
    "        embeddings = [embedding_function.embed_query(chunk) for chunk in new_chunks]\n",
    "        vectorstore.add_texts(texts=new_chunks, embeddings=embeddings)\n",
    "        print(f\"Inserted {len(new_chunks)} new chunks.\")\n",
    "    else:\n",
    "        print(\"No new data to insert.\")\n",
    "\n",
    "# Example usage\n",
    "vectorstore = insert_if_not_exists(\n",
    "    chunks=chunks, \n",
    "    embedding_function=embeddings_ollama, \n",
    "    vectorstore_path=\"data/vectorstore/chromadb\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer\n",
    "the question. If you don't know the answer, say that you\n",
    "don't know. DON'T MAKE UP ANYTHING.\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\"\n",
    "vectorstore_path='data/vectorstore/chromadb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_data_from_vectorstore(question):\n",
    "    try:\n",
    "        vectorstore = Chroma(persist_directory=vectorstore_path, embedding_function=embeddings_ollama)\n",
    "        retriever = vectorstore.as_retriever(search_type=\"similarity\")\n",
    "        relevant_chunks = retriever.invoke(\"who will provide adequate legal protection against the manufature of devices which have purpose of bypassing a technological protection measure.\")\n",
    "        print (relevant_chunks)\n",
    "        def format_docs(docs):\n",
    "            return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "        rag_chain = (\n",
    "            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt_template\n",
    "            | model_ollama\n",
    "        )\n",
    "        response = rag_chain.invoke(question)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return \"An error occurred while retrieving data.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "retrieve_data_from_vectorstore(\"who will provide adequate legal protection against the manufature of devices which have purpose of bypassing a technological protection measure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "embedding_function=embeddings_ollama\n",
    "vectorstore_path='data/vectorstore_test'\n",
    "vectorstore = Chroma.from_texts(texts=['con meo ngu ngoc','con ca biet di'], embedding=embedding_function, persist_directory=vectorstore_path)\n",
    "embedding = embedding_function.embed_query('con meo ngu ngoc')\n",
    "results = vectorstore.similarity_search_by_vector(embedding, k=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma(persist_directory=\"data/vectorstore_test\", embedding_function=embeddings_ollama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retriever and get relevant chunks\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\")\n",
    "relevant_chunks = retriever.invoke(\"who will provide adequate legal protection against the manufature of devices, products or components or the provision of services which:\")\n",
    "relevant_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate context text\n",
    "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in relevant_chunks])\n",
    "context_text\n",
    "# # Create prompt\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = prompt_template.format(context=context_text, \n",
    "                                question=\"who will provide adequate legal protection against the manufature of devices which have purpose of bypassing a technological protection measure.\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ollama.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\")\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "rag_chain = (\n",
    "            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt_template\n",
    "            | model_ollama\n",
    "        )\n",
    "rag_chain.invoke(\"who will provide adequate legal protection against the manufature of devices which have purpose of bypassing a technological protection measure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def get_visible_text_from_html(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to retrieve the webpage.\")\n",
    "        return None\n",
    "\n",
    "    print(\"Internet connected\")\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    for element in soup(['script', 'style']):\n",
    "        element.decompose()\n",
    "    text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "    lines = [line.strip() for line in text.splitlines() if line.strip()]\n",
    "    full_text = \"\\n\".join(lines)\n",
    "\n",
    "    print(\"Data collected\")\n",
    "    return full_text\n",
    "\n",
    "\n",
    "url = 'https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32019L1024'\n",
    "text_content = get_visible_text_from_html(url)\n",
    "print(\"Final collected text:\", text_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.functions import retrieve_answer, clear_vectorstore,categories_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No vectorstore found at 'data/vectorstore'.\n",
      "Processing category: Intellectual Property\n",
      "Internet connected\n",
      "Data collected\n",
      "Inserted 45 new chunks.\n",
      "URL https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32001L0029 has been logged as processed.\n",
      "Internet connected\n",
      "Data collected\n",
      "Inserted 138 new chunks.\n",
      "URL https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32019L0790 has been logged as processed.\n",
      "Internet connected\n",
      "Data collected\n",
      "Inserted 27 new chunks.\n",
      "URL https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:31996L0009 has been logged as processed.\n",
      "Internet connected\n",
      "Data collected\n",
      "Inserted 55 new chunks.\n",
      "URL https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32016L0943 has been logged as processed.\n",
      "Processing category: Artificial Intelligence\n",
      "Internet connected\n",
      "Data collected\n",
      "Inserted 504 new chunks.\n",
      "URL https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ:L_202401689 has been logged as processed.\n",
      "Processing category: Digital Services\n",
      "Internet connected\n",
      "Data collected\n",
      "Inserted 70 new chunks.\n",
      "URL https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32022R2056 has been logged as processed.\n",
      "Processing category: Data Protection\n",
      "Internet connected\n",
      "Data collected\n",
      "Inserted 303 new chunks.\n",
      "URL https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32016R0679 has been logged as processed.\n",
      "Processing category: Competition Law\n",
      "Internet connected\n",
      "Data collected\n",
      "Inserted 2 new chunks.\n",
      "URL https://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX%3A12008E101%3AEN%3AHTML has been logged as processed.\n",
      "Internet connected\n",
      "Data collected\n",
      "Inserted 1 new chunks.\n",
      "URL https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX%3A12008E102 has been logged as processed.\n",
      "Internet connected\n",
      "Data collected\n",
      "Inserted 220 new chunks.\n",
      "URL https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32022R1925 has been logged as processed.\n",
      "Processing category: Data Governance\n",
      "Data is already in the vectorstore\n",
      "Internet connected\n",
      "Data collected\n",
      "Inserted 159 new chunks.\n",
      "URL https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32022R0868 has been logged as processed.\n"
     ]
    }
   ],
   "source": [
    "clear_vectorstore('data/vectorstore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "model_ollama = ChatOllama(model=\"llama3.2\", temperature=0)\n",
    "embeddings_ollama = OllamaEmbeddings(model=\"MXBAI-EMBED-LARGE\")\n",
    "vectorstore = Chroma(persist_directory='data/vectorstores/Intellectual_Property', embedding_function=embeddings_ollama)\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\")\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "rag_chain = (\n",
    "{\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "| prompt_template\n",
    "| model_ollama\n",
    ")\n",
    "response = rag_chain.invoke('Who is Bob?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't know who Bob is, as there is no mention of a person named Bob in the provided context.\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2024-11-10T18:19:50.656761Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 7209729167, 'load_duration': 20854042, 'prompt_eval_count': 802, 'prompt_eval_duration': 5436000000, 'eval_count': 24, 'eval_duration': 1752000000}, id='run-55108460-efc0-4543-b4cc-b145a564dcbc-0', usage_metadata={'input_tokens': 802, 'output_tokens': 24, 'total_tokens': 826})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
